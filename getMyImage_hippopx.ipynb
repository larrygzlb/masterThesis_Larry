{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.hippopx.com/en/query?q=Temple&page={}\"\n",
    "\n",
    "def get_image_links_from_page(page_number):\n",
    "    response = requests.get(BASE_URL.format(page_number))\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    img_tags = soup.find_all('img', {'data-src': True})\n",
    "\n",
    "    img_links = [img['data-src'] for img in img_tags]\n",
    "    return img_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(links, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    for i, link in enumerate(links):\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open(f\"{destination_folder}/image_{i}.jpg\", 'wb') as out_file:\n",
    "            for chunk in response.iter_content(8192):\n",
    "                out_file.write(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(img_links, \"./myImage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 20...\n",
      "Processing page 21...\n",
      "Processing page 22...\n",
      "Processing page 23...\n",
      "Processing page 24...\n",
      "Processing page 25...\n",
      "Processing page 26...\n",
      "Processing page 27...\n",
      "Processing page 28...\n",
      "Processing page 29...\n",
      "Processing page 30...\n",
      "Processing page 31...\n",
      "Processing page 32...\n",
      "Processing page 33...\n",
      "Processing page 34...\n",
      "Processing page 35...\n",
      "Processing page 36...\n",
      "Processing page 37...\n",
      "Processing page 38...\n",
      "Processing page 39...\n",
      "Processing page 40...\n",
      "Processing page 41...\n",
      "Processing page 42...\n",
      "Processing page 43...\n",
      "Processing page 44...\n",
      "Processing page 45...\n",
      "Processing page 46...\n",
      "Processing page 47...\n",
      "Processing page 48...\n",
      "Processing page 49...\n",
      "Processing page 50...\n",
      "Processing page 51...\n",
      "Processing page 52...\n",
      "Processing page 53...\n",
      "Processing page 54...\n",
      "Processing page 55...\n",
      "Processing page 56...\n",
      "Processing page 57...\n",
      "Processing page 58...\n",
      "Processing page 59...\n",
      "Processing page 60...\n",
      "Processing page 61...\n",
      "Processing page 62...\n",
      "Processing page 63...\n",
      "Processing page 64...\n",
      "Processing page 65...\n",
      "Processing page 66...\n",
      "Processing page 67...\n",
      "Processing page 68...\n",
      "Processing page 69...\n",
      "Processing page 70...\n",
      "Processing page 71...\n",
      "Processing page 72...\n",
      "Processing page 73...\n",
      "Processing page 74...\n",
      "Processing page 75...\n",
      "Processing page 76...\n",
      "Processing page 77...\n",
      "Processing page 78...\n",
      "Processing page 79...\n",
      "Processing page 80...\n",
      "Processing page 81...\n",
      "Processing page 82...\n",
      "Processing page 83...\n",
      "Processing page 84...\n",
      "Processing page 85...\n",
      "Processing page 86...\n",
      "Processing page 87...\n",
      "Processing page 88...\n",
      "Processing page 89...\n",
      "Processing page 90...\n",
      "Processing page 91...\n",
      "Processing page 92...\n",
      "Processing page 93...\n",
      "Processing page 94...\n",
      "Processing page 95...\n",
      "Processing page 96...\n",
      "Processing page 97...\n",
      "Processing page 98...\n",
      "Processing page 99...\n",
      "Processing page 100...\n",
      "Processing page 101...\n",
      "Processing page 102...\n",
      "Processing page 103...\n",
      "Processing page 104...\n",
      "Processing page 105...\n",
      "Processing page 106...\n",
      "Processing page 107...\n",
      "Processing page 108...\n",
      "Processing page 109...\n",
      "Processing page 110...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "BASE_URL = \"https://www.hippopx.com/en/query?q=Temple&page={}\"\n",
    "\n",
    "def get_image_links_from_page(page_number):\n",
    "    response = requests.get(BASE_URL.format(page_number))\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    img_tags = soup.find_all('img', {'src': True})\n",
    "    img_links = [img['src'] for img in img_tags]\n",
    "    return img_links\n",
    "\n",
    "# 全局图片计数器\n",
    "global_image_counter = 0\n",
    "\n",
    "def download_images(links, destination_folder):\n",
    "    global global_image_counter\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    for link in links:\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open(f\"{destination_folder}/image_{global_image_counter}.jpg\", 'wb') as out_file:\n",
    "            for chunk in response.iter_content(8192):\n",
    "                out_file.write(chunk)\n",
    "        global_image_counter += 1\n",
    "\n",
    "destination_folder = \"./myImage\"\n",
    "\n",
    "# 下载从第1页到第100页的图片\n",
    "for page in range(1, 111):  # 从1到100\n",
    "    print(f\"Processing page {page}...\")\n",
    "    links = get_image_links_from_page(page)\n",
    "    download_images(links, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, 101):  # 从1到100\n",
    "    print(f\"Processing page {page}...\")\n",
    "    links = get_image_links_from_page(page)\n",
    "    download_images(links, destination_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusionModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
